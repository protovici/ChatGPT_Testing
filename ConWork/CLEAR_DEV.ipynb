{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Code runs, but does not have ClEAR Value Label and service catalog whos up duplicate instance for the opportunity items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to format revenue and date\n",
    "def format_revenue_and_date(revenue, date):\n",
    "    revenue_text = f\" - ${revenue:,.0f}\" if pd.notnull(revenue) else \"\"\n",
    "    date_text = f\" - {date.strftime('%m/%d/%Y')}\" if pd.notnull(date) else \"\"\n",
    "    return revenue_text + date_text\n",
    "\n",
    "# Function to calculate 'CLEAR Value'\n",
    "def calculate_clear_value(transactions):\n",
    "    total_revenue = transactions['Revenue'].sum()\n",
    "    last_transaction_date = transactions['Transaction Date'].max()\n",
    "    divisions = transactions['Division'].unique()\n",
    "    \n",
    "    if len(divisions) == 0:\n",
    "        return \"Opportunity\"\n",
    "    elif len(divisions) > 1:\n",
    "        service_text = \"Both\"\n",
    "    else:\n",
    "        service_text = divisions[0]\n",
    "        \n",
    "    return service_text + format_revenue_and_date(total_revenue, last_transaction_date)\n",
    "\n",
    "# Load transactional data and service catalog\n",
    "transactional_data_path = r'C:\\Users\\proto\\OneDrive\\ConWork\\synthetic_project_clear_data_DEV.xlsx'  # Update with the actual path\n",
    "service_catalog_path = r'C:\\Users\\proto\\OneDrive\\ConWork\\service_catalog.txt'  # Update with the actual path\n",
    "\n",
    "transactions_df = pd.read_excel(transactional_data_path)\n",
    "service_catalog_df = pd.read_csv(service_catalog_path, delimiter='\\t')\n",
    "\n",
    "# Identifying unique combinations of service categories and subservice categories from the service catalog\n",
    "valid_combinations = service_catalog_df.drop_duplicates(subset=['Service Category', 'SubService Category'])\n",
    "\n",
    "# Identify unique services provided to each client and calculate 'CLEAR Value'\n",
    "unique_services = transactions_df.groupby(['Client Name', 'Service Category', 'SubService Category']).apply(calculate_clear_value).reset_index(name='CLEAR Value')\n",
    "\n",
    "# Join the 'CLEAR Value' back to the transactional data\n",
    "enhanced_transactions_df = pd.merge(transactions_df, unique_services, on=['Client Name', 'Service Category', 'SubService Category'], how='left')\n",
    "\n",
    "# Create a DataFrame of all possible combinations of clients and VALID service catalog entries\n",
    "clients = transactions_df['Client Name'].unique()\n",
    "all_possible_services = pd.MultiIndex.from_product([clients, valid_combinations['Service Category'], valid_combinations['SubService Category']], names=['Client Name', 'Service Category', 'SubService Category']).to_frame(index=False)\n",
    "\n",
    "# Filter out combinations that don't exist in the service catalog\n",
    "valid_service_combinations = all_possible_services.merge(valid_combinations, on=['Service Category', 'SubService Category'], how='inner')\n",
    "\n",
    "# Find services from the catalog not provided to each client and mark as 'Opportunity'\n",
    "opportunities = pd.merge(valid_service_combinations, unique_services, on=['Client Name', 'Service Category', 'SubService Category'], how='left', indicator=True)\n",
    "opportunities = opportunities[opportunities['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "opportunities['CLEAR Value'] = \"Opportunity\"\n",
    "\n",
    "# Combine provided services with opportunities\n",
    "final_df = pd.concat([enhanced_transactions_df, opportunities])\n",
    "\n",
    "# Add missing columns for opportunities with NaN values\n",
    "missing_cols = set(transactions_df.columns) - set(final_df.columns)\n",
    "for col in missing_cols:\n",
    "    final_df[col] = pd.NA\n",
    "\n",
    "# Rearrange columns to match the original transactional data\n",
    "final_df = final_df[transactions_df.columns.tolist() + ['CLEAR Value']]\n",
    "\n",
    "# Current timestamp to append to the file name\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "final_output_path = f'C:\\\\Users\\\\proto\\\\OneDrive\\\\ConWork\\\\final_output_{timestamp}.csv'\n",
    "\n",
    "# Output the final DataFrame to a CSV file\n",
    "final_df.to_csv(final_output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Code works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\GitHub\\ChatGPT_Testing\\ConWork\\CLEAR_DEV.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GitHub/ChatGPT_Testing/ConWork/CLEAR_DEV.ipynb#X10sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     last_transaction_date \u001b[39m=\u001b[39m transactions[\u001b[39m'\u001b[39m\u001b[39mTransaction Date\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmax()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GitHub/ChatGPT_Testing/ConWork/CLEAR_DEV.ipynb#X10sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m row[\u001b[39m'\u001b[39m\u001b[39mCLEAR Value Label\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m format_revenue_and_date(total_revenue, last_transaction_date)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/GitHub/ChatGPT_Testing/ConWork/CLEAR_DEV.ipynb#X10sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m unique_services_label[\u001b[39m'\u001b[39m\u001b[39mCLEAR Value\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m unique_services_label\u001b[39m.\u001b[39;49mapply(calculate_clear_value, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GitHub/ChatGPT_Testing/ConWork/CLEAR_DEV.ipynb#X10sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# Create a DataFrame of all possible combinations of clients and VALID service catalog entries\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GitHub/ChatGPT_Testing/ConWork/CLEAR_DEV.ipynb#X10sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m clients \u001b[39m=\u001b[39m transactions_df[\u001b[39m'\u001b[39m\u001b[39mClient Name\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()\n",
      "File \u001b[1;32mc:\\Code Languages\\Python\\3.11.5\\Lib\\site-packages\\pandas\\core\\frame.py:10037\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m  10025\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10027\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[0;32m  10028\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m  10029\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10035\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m  10036\u001b[0m )\n\u001b[1;32m> 10037\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Code Languages\\Python\\3.11.5\\Lib\\site-packages\\pandas\\core\\apply.py:837\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    834\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[0;32m    835\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[1;32m--> 837\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Code Languages\\Python\\3.11.5\\Lib\\site-packages\\pandas\\core\\apply.py:963\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 963\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[0;32m    965\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m    966\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Code Languages\\Python\\3.11.5\\Lib\\site-packages\\pandas\\core\\apply.py:979\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    977\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[0;32m    978\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 979\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(v, \u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[0;32m    980\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    981\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    982\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    983\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32mc:\\GitHub\\ChatGPT_Testing\\ConWork\\CLEAR_DEV.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GitHub/ChatGPT_Testing/ConWork/CLEAR_DEV.ipynb#X10sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculate_clear_value\u001b[39m(row):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GitHub/ChatGPT_Testing/ConWork/CLEAR_DEV.ipynb#X10sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     transactions \u001b[39m=\u001b[39m transactions_df[(transactions_df[\u001b[39m'\u001b[39m\u001b[39mClient Name\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mClient Name\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m&\u001b[39m \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/GitHub/ChatGPT_Testing/ConWork/CLEAR_DEV.ipynb#X10sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m                                    (transactions_df[\u001b[39m'\u001b[39;49m\u001b[39mService Category\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39;49m row[\u001b[39m'\u001b[39;49m\u001b[39mService Category\u001b[39;49m\u001b[39m'\u001b[39;49m]) \u001b[39m&\u001b[39m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GitHub/ChatGPT_Testing/ConWork/CLEAR_DEV.ipynb#X10sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m                                    (transactions_df[\u001b[39m'\u001b[39m\u001b[39mSubService Category\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mSubService Category\u001b[39m\u001b[39m'\u001b[39m])]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GitHub/ChatGPT_Testing/ConWork/CLEAR_DEV.ipynb#X10sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     total_revenue \u001b[39m=\u001b[39m transactions[\u001b[39m'\u001b[39m\u001b[39mRevenue\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msum()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GitHub/ChatGPT_Testing/ConWork/CLEAR_DEV.ipynb#X10sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     last_transaction_date \u001b[39m=\u001b[39m transactions[\u001b[39m'\u001b[39m\u001b[39mTransaction Date\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmax()\n",
      "File \u001b[1;32mc:\\Code Languages\\Python\\3.11.5\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[1;32mc:\\Code Languages\\Python\\3.11.5\\Lib\\site-packages\\pandas\\core\\arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__eq__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__eq__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m---> 40\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cmp_method(other, operator\u001b[39m.\u001b[39;49meq)\n",
      "File \u001b[1;32mc:\\Code Languages\\Python\\3.11.5\\Lib\\site-packages\\pandas\\core\\series.py:5799\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   5796\u001b[0m lvalues \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values\n\u001b[0;32m   5797\u001b[0m rvalues \u001b[39m=\u001b[39m extract_array(other, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, extract_range\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m-> 5799\u001b[0m res_values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mcomparison_op(lvalues, rvalues, op)\n\u001b[0;32m   5801\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(res_values, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Code Languages\\Python\\3.11.5\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:346\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    343\u001b[0m     \u001b[39mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[0;32m    345\u001b[0m \u001b[39melif\u001b[39;00m lvalues\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(rvalues, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 346\u001b[0m     res_values \u001b[39m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[0;32m    348\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Code Languages\\Python\\3.11.5\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:132\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    131\u001b[0m     result \u001b[39m=\u001b[39m libops\u001b[39m.\u001b[39mscalar_compare(x\u001b[39m.\u001b[39mravel(), y, op)\n\u001b[1;32m--> 132\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39;49mreshape(x\u001b[39m.\u001b[39;49mshape)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to calculate 'CLEAR Value Label'\n",
    "def calculate_clear_value_label(transactions):\n",
    "    divisions = transactions['Division'].unique()\n",
    "    if len(divisions) == 0:\n",
    "        return \"Opportunity\"\n",
    "    elif len(divisions) > 1:\n",
    "        return \"Both\"\n",
    "    else:\n",
    "        return divisions[0]\n",
    "\n",
    "# Function to format revenue and date\n",
    "def format_revenue_and_date(revenue, date):\n",
    "    revenue_text = f\" - ${revenue:,.0f}\" if pd.notnull(revenue) else \"\"\n",
    "    date_text = f\" - {date.strftime('%m/%d/%Y')}\" if pd.notnull(date) else \"\"\n",
    "    return revenue_text + date_text\n",
    "\n",
    "# Load transactional data and service catalog\n",
    "transactional_data_path = r'C:\\Users\\proto\\OneDrive\\ConWork\\synthetic_project_clear_data_DEV.xlsx'  # Update with the actual path\n",
    "service_catalog_path = r'C:\\Users\\proto\\OneDrive\\ConWork\\service_catalog.txt'  # Update with the actual path\n",
    "\n",
    "transactions_df = pd.read_excel(transactional_data_path)\n",
    "service_catalog_df = pd.read_csv(service_catalog_path, delimiter='\\t')\n",
    "\n",
    "# Identifying unique combinations from the service catalog\n",
    "valid_combinations = service_catalog_df.drop_duplicates(subset=['Service Category', 'SubService Category'])\n",
    "\n",
    "# Calculate 'CLEAR Value Label' for each unique service provided\n",
    "grouped = transactions_df.groupby(['Client Name', 'Service Category', 'SubService Category'])\n",
    "unique_services_label = grouped.apply(calculate_clear_value_label).reset_index(name='CLEAR Value Label')\n",
    "\n",
    "# Calculate 'CLEAR Value' for each unique service provided\n",
    "def calculate_clear_value(row):\n",
    "    transactions = transactions_df[(transactions_df['Client Name'] == row['Client Name']) & \n",
    "                                   (transactions_df['Service Category'] == row['Service Category']) & \n",
    "                                   (transactions_df['SubService Category'] == row['SubService Category'])]\n",
    "    total_revenue = transactions['Revenue'].sum()\n",
    "    last_transaction_date = transactions['Transaction Date'].max()\n",
    "    return row['CLEAR Value Label'] + format_revenue_and_date(total_revenue, last_transaction_date)\n",
    "\n",
    "unique_services_label['CLEAR Value'] = unique_services_label.apply(calculate_clear_value, axis=1)\n",
    "\n",
    "# Create a DataFrame of all possible combinations of clients and VALID service catalog entries\n",
    "clients = transactions_df['Client Name'].unique()\n",
    "all_possible_services = pd.MultiIndex.from_product([clients, valid_combinations['Service Category'], valid_combinations['SubService Category']], names=['Client Name', 'Service Category', 'SubService Category']).to_frame(index=False)\n",
    "\n",
    "# Find services from the catalog not provided to each client and mark as 'Opportunity'\n",
    "opportunities = pd.merge(all_possible_services, unique_services_label, on=['Client Name', 'Service Category', 'SubService Category'], how='left', indicator=True)\n",
    "opportunities = opportunities[opportunities['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "opportunities['CLEAR Value Label'] = \"Opportunity\"\n",
    "opportunities['CLEAR Value'] = \"Opportunity\"\n",
    "\n",
    "# Combine provided services with opportunities\n",
    "final_df = pd.concat([unique_services_label, opportunities])\n",
    "\n",
    "# Add missing columns for opportunities with NaN values\n",
    "missing_cols = set(transactions_df.columns) - set(final_df.columns)\n",
    "for col in missing_cols:\n",
    "    final_df[col] = pd.NA\n",
    "\n",
    "# Rearrange columns to match the original transactional data and include 'CLEAR Value Label' and 'CLEAR Value'\n",
    "final_df = final_df[transactions_df.columns.tolist() + ['CLEAR Value Label', 'CLEAR Value']]\n",
    "\n",
    "# Current timestamp to append to the file name and output the final DataFrame\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "final_output_path = f'C:\\\\Users\\\\proto\\\\OneDrive\\\\ConWork\\\\final_output_{timestamp}.csv'\n",
    "final_df.to_csv(final_output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code restructured to run quicker, but needs attention to logic of non transactional items and fomatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load transactional data and service catalog\n",
    "transactional_data_path = r'C:\\Users\\proto\\OneDrive\\ConWork\\synthetic_project_clear_data_DEV.xlsx'\n",
    "service_catalog_path = r'C:\\Users\\proto\\OneDrive\\ConWork\\service_catalog.txt'\n",
    "\n",
    "transactions_df = pd.read_excel(transactional_data_path)\n",
    "service_catalog_df = pd.read_csv(service_catalog_path, delimiter='\\t')\n",
    "\n",
    "# Vectorized calculation of 'CLEAR Value Label'\n",
    "def vectorized_clear_value_label(df):\n",
    "    df['CLEAR Value Label'] = df['Division']\n",
    "    df.loc[df['Division'].duplicated(keep=False), 'CLEAR Value Label'] = 'Both'\n",
    "    df['CLEAR Value Label'].fillna('Opportunity', inplace=True)\n",
    "    return df\n",
    "\n",
    "transactions_df = vectorized_clear_value_label(transactions_df)\n",
    "\n",
    "# Function to format revenue and date\n",
    "def format_revenue_and_date(revenue, date):\n",
    "    revenue_text = f\" - ${revenue:,.0f}\" if pd.notnull(revenue) and revenue >= 0 else \"\"\n",
    "    date_text = f\" - {date.strftime('%m/%d/%Y')}\" if pd.notnull(date) else \"\"\n",
    "    return revenue_text + date_text\n",
    "\n",
    "# Calculate 'CLEAR Value'\n",
    "transactions_df['CLEAR Value'] = transactions_df.apply(lambda row: row['CLEAR Value Label'] + format_revenue_and_date(row['Revenue'], row['Transaction Date']), axis=1)\n",
    "\n",
    "# Prepare for opportunities calculation\n",
    "valid_combinations = service_catalog_df.drop_duplicates(subset=['Service Category', 'SubService Category'])\n",
    "clients = transactions_df['Client Name'].unique()\n",
    "all_possible_services = pd.MultiIndex.from_product([clients, valid_combinations['Service Category'], valid_combinations['SubService Category']], names=['Client Name', 'Service Category', 'SubService Category']).to_frame(index=False)\n",
    "\n",
    "# Calculate opportunities\n",
    "opportunities = pd.merge(all_possible_services, transactions_df[['Client Name', 'Service Category', 'SubService Category', 'CLEAR Value']], on=['Client Name', 'Service Category', 'SubService Category'], how='left', indicator=True)\n",
    "opportunities = opportunities[opportunities['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "opportunities['CLEAR Value'] = \"Opportunity\"\n",
    "\n",
    "# Combine provided services with opportunities\n",
    "final_df = pd.concat([transactions_df, opportunities], ignore_index=True)\n",
    "\n",
    "# Add missing columns for opportunities with NaN values\n",
    "missing_cols = set(transactions_df.columns) - set(final_df.columns)\n",
    "for col in missing_cols:\n",
    "    final_df[col] = pd.NA\n",
    "\n",
    "# Rearrange columns to match the original transactional data\n",
    "final_df = final_df[transactions_df.columns.tolist() + ['CLEAR Value Label', 'CLEAR Value']]\n",
    "\n",
    "# Current timestamp to append to the file name and output the final DataFrame\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "final_output_path = f'C:\\\\Users\\\\proto\\\\OneDrive\\\\ConWork\\\\final_output_{timestamp}.csv'\n",
    "final_df.to_csv(final_output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
